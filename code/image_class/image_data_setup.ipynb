{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Images dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import cv2\n",
    "import h5py\n",
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from PIL import Image\n",
    "import ZipFile\n",
    "import tarfile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we setup the training, validation and testing dataset for the image classification task. We used the [UTKFace](https://susanqq.github.io/UTKFace/) dataset for training, and testing on our own scrapped profile pictures from the nannies, to obtained them you'll have to run the image_scrapper.R script, providing the urls from the urls from the user_ages.csv file. \n",
    "\n",
    "First we download the zip file from the link above and use the `ZipFile` and `tarfile` packages to extract them. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'your_path'\n",
    "target_dir = ''\n",
    "with ZipFile('UTKface_inthewild.zip', 'r') as f:\n",
    "  f.extractall(target_dir)\n",
    "\n",
    "target_dir = ''\n",
    "for file in os.listdir(target_dir):\n",
    "  with tarfile.open(path + file, 'r:gz') as f:\n",
    "    f.extractall(target_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next cell is to resize all images in a directory, it's not necessary, but if you want to do it run it in a local machine rather than google colab. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sizes = []\n",
    "wild_files = []\n",
    "new_size = (256,256)\n",
    "dir = '../data/part2/'\n",
    "for file in os.listdir(dir):\n",
    "    filepath = os.path.join(dir, file)\n",
    "    try: \n",
    "        img = Image.open(filepath)\n",
    "        sizes.append(img.size)\n",
    "        if img.size != new_size:\n",
    "            img.resize(new_size).convert('RGB').save(filepath)\n",
    "            #sizes.append(img.size)\n",
    "            wild_files.append(filepath)\n",
    "    except:\n",
    "        #os.remove(filepath)\n",
    "        print(filepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next function is to build a csv file, containing the file path and other information in the UTKFace image dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def class_labels_reassign(age):\n",
    "    if 10 <= age <= 20:\n",
    "        return 0\n",
    "    elif 21 <= age <= 27:\n",
    "        return 1\n",
    "    elif 28 <= age <= 45:\n",
    "        return 2\n",
    "    elif 46 <= age <= 65:\n",
    "        return 3\n",
    "    else:\n",
    "        return 4\n",
    "\n",
    "\n",
    "def build_csv(directory, output_csv_name):\n",
    "    \"\"\"\n",
    "    Builds a csv file for pytorch training from a directory of folders of images.\n",
    "    Install csv module if not already installed.\n",
    "    Args:\n",
    "    directory_string: string of directory path, e.g. r'.\\data\\train'\n",
    "    output_csv_name: string of output csv file name, e.g. 'train.csv'\n",
    "    Returns:\n",
    "    csv file with file names, file paths, class names and class indices\n",
    "    \"\"\"\n",
    "\n",
    "    file_lst = os.listdir(directory) #returns a LIST containing the names of the entries (folder names in this case) in the directory.\n",
    "    #class_lst.sort() #IMPORTANT\n",
    "    with open(output_csv_name, 'w', newline='') as csvfile:\n",
    "        writer = csv.writer(csvfile, delimiter=',')\n",
    "        writer.writerow(['file_name', 'file_path', 'age', 'age_class', 'gender', 'race']) #create column names\n",
    "        for img_file in file_lst:\n",
    "            img_path = os.path.join(directory, img_file) #concatenates various path components with exactly one directory separator (‘/’) except the last path component.\n",
    "            name_components = img_file.split('_')\n",
    "            if len(name_components) == 4:\n",
    "              age, gender, race, _ = name_components\n",
    "              if int(age) >= 14:\n",
    "                writer.writerow([img_file, img_path, age, class_labels_reassign(float(age)), gender, race]) #write the file path and class name to the csv file\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "datapath = \"../../data/input/\"\n",
    "build_csv(datapath + \"images/part1\", datapath + \"part1.csv\")\n",
    "build_csv(datapath + \"images/part2\", datapath + \"part2.csv\")\n",
    "build_csv(datapath + \"images/part3\", datapath + \"part3.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this cell we create a csv for the users' profile picture. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file file ready\n"
     ]
    }
   ],
   "source": [
    "directory = datapath + \"images/profile_pics/\"\n",
    "output_csv = datapath + \"nannies_test.csv\"\n",
    "file_list = os.listdir(directory)\n",
    "    # Get user ages\n",
    "user_ages = pd.read_csv(\"../../data/output/python_tests/user_ages.csv\")\n",
    "with open(output_csv, \"w\") as csvfile:\n",
    "    writer = csv.writer(csvfile, delimiter=',')\n",
    "    writer.writerow(['file_name', 'file_path', 'age', 'age_class'])\n",
    "    for img_file in file_list:\n",
    "      img_path = os.path.join(directory, img_file)\n",
    "      img_id = int(img_file.split('.')[0])\n",
    "      ages_df = user_ages[user_ages.id == img_id][\"age\"]\n",
    "      if ages_df.any():\n",
    "        age = ages_df.values[0]\n",
    "        writer.writerow([img_file, img_path, age, class_labels_reassign(age)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We apply some transformations to the train and validation sets to make them more similar to our test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "datapath = \"../../data/input/\"\n",
    "class_names = [\"10-20\", \"21-27\", \"28-45\", \"46-65\", \"65+\"]\n",
    "part1 = pd.read_csv(datapath + 'part1.csv')\n",
    "part2 = pd.read_csv(datapath + 'part2.csv')\n",
    "test = pd.read_csv(datapath + 'nannies_test.csv').dropna()\n",
    "test.to_csv(datapath + 'nannies_test.csv')\n",
    "\n",
    "train = pd.concat([part1, part2]).reset_index(drop=True)\n",
    "train = train[(train.age > test.age.min()) & (train.age < test.age.max() + 10)].reset_index(drop=True)\n",
    "train.to_csv(datapath + 'train.csv', index=False)\n",
    "\n",
    "validation = pd.read_csv(datapath + 'part3.csv')\n",
    "validation = validation[(validation.age > test.age.min()) & (validation.age < test.age.max() + 10)].reset_index(drop=True)\n",
    "validation.to_csv(datapath + 'validation.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this function we create a h5py file that stores the images, ages and age class in numpy arrays rather than jpeg, which will make the model run way faster. If possible run this cell on a local machine rather than google colab, since it will loop through all images which will be very slow on colab. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_h5py_file(filename, dataframe, size: tuple):\n",
    "    n = len(dataframe)\n",
    "    x_shape = (n,) + size\n",
    "    y_shape = (n,)\n",
    "    with h5py.File(filename, \"w\") as out:\n",
    "        X = out.create_dataset(\"X\", x_shape, dtype=\"u1\")\n",
    "        age = out.create_dataset(\"age\", y_shape, dtype=\"u1\")\n",
    "        age_class = out.create_dataset(\"age_class\", y_shape, dtype=\"u1\")\n",
    "\n",
    "        age[:] = dataframe.loc[:,\"age\"].values#.reshape(-1, 1, 1)\n",
    "        age_class[:] = dataframe.loc[:,\"age_class\"].values#.reshape(-1, 1, 1)\n",
    "\n",
    "        for i, file in enumerate(dataframe.loc[:, \"file_path\"]):\n",
    "            img = cv2.imread(file)\n",
    "            if img.shape != size:\n",
    "              img = cv2.resize(img, size[:2], interpolation=cv2.INTER_AREA)\n",
    "            X[i:i+1:,:,:,:] = img\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_size = (256, 256, 3)\n",
    "create_h5py_file(datapath + 'train.h5', train, size=correct_size)\n",
    "create_h5py_file(datapath + 'validation.h5', validation, size=correct_size)\n",
    "create_h5py_file(datapath + 'test.h5', test, size=correct_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_size = (30, 30, 3)\n",
    "create_h5py_file(datapath + 'train-30.h5', train, size=correct_size)\n",
    "create_h5py_file(datapath + 'validation-30.h5', validation, size=correct_size)\n",
    "create_h5py_file(datapath + 'test-30.h5', test, size=correct_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next up we create a pytorch dataset based on the h5py file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "class dataset_h5(torch.utils.data.Dataset):\n",
    "    def __init__(self, in_file, transform=None):\n",
    "        super(dataset_h5, self).__init__()\n",
    " \n",
    "        self.file = h5py.File(in_file, 'r')\n",
    "        self.transform = transform\n",
    " \n",
    "    def __getitem__(self, index):\n",
    "        x = self.file['X'][index, ...]\n",
    "        age = self.file['age'][index, ...]\n",
    "        age_class = self.file['age_class'][index, ...]\n",
    "        \n",
    "        # Preprocessing each image\n",
    "        if self.transform is not None:\n",
    "            x = self.transform(x)        \n",
    "        \n",
    "        return x, age, age_class\n",
    " \n",
    "    def __len__(self):\n",
    "        return self.file['X'].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(256, 256, 3)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset = dataset_h5(datapath + 'test-1.h5')\n",
    "test_dataset[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = dataset_h5(datapath + 'train-30.h5')\n",
    "train_dataset[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
