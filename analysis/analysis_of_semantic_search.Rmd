---
title: "Analysis of semantic search results"
output: pdf_document
---

```{r setup, include=FALSE}
# knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(
  echo = FALSE,
  message = FALSE,
  warning = FALSE,
  error = FALSE, 
  out.width = "100%",
  fig.width = 10,
  fig.height = 3.2, 
  fig.retina = 3,
  fig.pos = "H",
  cache = FALSE)
```

```{r include=FALSE, echo=FALSE}
library(tidyverse)
library(gridExtra)
library(kableExtra)
library(knitr)
library(tidytext)
library(igraph)
library(ggraph)
```
In this notebook we will analyze the results from the information retrieval task from profile descriptions of nannies obtained from the site [CareGuide: CanadianNanny.ca](https://canadiannanny.ca/) [1]. So far we have retrieved around 9k+ distinct profile descriptions from all over Canada. The goal is to extract demographic information from the text such as age, gender, nationality and immigration status, and analyze these in order to find systemic inequalities and discrimination. These variables were obtained using information retrieval techniques with two different approaches: a lexical keyword-base model, such as BM25, and semantic search with transformer-generated sentence embeddings. 

```{r include=FALSE}
data <- read.csv("../data/input/nannies_profiles_canada.csv") |> 
  mutate(date = as.Date(date)) |> 
  arrange(desc(date)) |> 
  distinct(link, .keep_all = T) |> 
  mutate(across(c(rate, years_exp, experience_children, num_reviews), 
                ~as.numeric(str_extract(., "\\d+(?:\\.\\d+)?"))),
         star_rating = ifelse(is.na(num_reviews), NA, star_rating), 
         num_reviews = ifelse(is.na(num_reviews), 0, num_reviews))
dim(data)
```

## Data
The profiles were scraped using an R script at multiple points of July, August and September. They were retrieved in order of appearance on the site which is sorted by the last time the user was active on the platform. So far more than 16,000 entries have been scraped from the site, of those around 9,700 are distinct users. To run the information retrieval tasks, duplicates were dropped keeping the latest profile update. 

Demographic variables are usually reported by the user in the text-based sections of their profiles, which include the short blurb right under the profile picture, a "Reasons to Hire Me" section, and a longer description in the "About Me" section. We also retrieved the users' name, url, location, reported years of experience, hourly rate, last time active on the site, number of reviews, star rating out of five, bullet points under the "I can work:" subsection (part-time, full-time, summer, etc.), children ages the user has experience with (infant, toddler, newborn, etc.), number of children they can look after, experience with children with medical conditions (diabetes, disability, epilepsy, severe allergies, etc.), transportation requirements (close to transit, has driver's license, etc.), qualifications (first aid, CPR, languages, etc.), and services they can provide (housekeeping, cooking, groceries, swim supervision, etc.).
```{r}
data |> 
  filter(!is.na(province)) |>
  filter(province != " Unorganized") |> 
  group_by(province) |> 
  summarise(`N (ratio)` = paste0(n(), 
                      " (", round(n()/dim(data)[1], 3), ")"), 
            `Rate (sd)` = paste0(round(mean(rate[rate < 200], na.rm = T), 3), 
                               " (", round(sd(rate[rate < 200], na.rm=T), 2), ")"), 
            `Years Ex. (sd)` = paste0(round(mean(years_exp[years_exp < 50], na.rm = T), 3), 
                               " (", round(sd(years_exp[years_exp < 50], na.rm=T), 2), ")"),
            `No. Children (sd)` = paste0(round(mean(experience_children, na.rm = T), 3), 
                               " (", round(sd(experience_children, na.rm=T), 2), ")"), 
            `Ratings (No. rev.)` = paste0(round(mean(star_rating, na.rm = T), 3), 
                               " (", sum(num_reviews, na.rm = T), ")")) |>
  add_row(province = "National", 
          `N (ratio)` = paste0(dim(data)[1], " (",1.000, ")"), 
          `Rate (sd)` = paste0(round(mean(data$rate[data$rate < 200], na.rm = T), 3), 
                              " (", round(sd(data$rate[data$rate < 200], na.rm=T), 2), ")"), 
          `Years Ex. (sd)` = paste0(round(mean(data$years_exp[data$years_exp < 50], na.rm = T), 3), 
                             " (", round(sd(data$years_exp[data$years_exp < 50], na.rm=T), 2), ")"),
          `No. Children (sd)` = paste0(round(mean(data$experience_children, na.rm = T), 3), 
                             " (", round(sd(data$experience_children, na.rm=T), 2), ")"), 
          `Ratings (No. rev.)` = paste0(round(mean(data$star_rating, na.rm = T), 3), 
                               " (", sum(data$num_reviews, na.rm = T), ")")) |>
  rename(`Province/Territory` = province) |> 
  kable(format="latex", booktabs = T, caption = "Province statistics") |>
  kable_styling(full_width = FALSE, latex_options = "hold_position") |> 
  row_spec(12, hline_after = T) |> 
  column_spec(1, width = "2.7cm")
```

### Exploratory Data Analysis
Table 1 shows average values (expect the first column) by province of specific characteristics reported by users, rates over $200 CAD hourly were removed, since these are probably a mistake. Ontario is by far the province with the most users with over 50% of these located there, followed by Alberta and British Columbia, which are both well over 1k users and above 15% of the total. At the national we have a mean hourly rate of \$19.51 CAD with a standard deviation of \$4.65, the province with highest rate in average was British Columbia with \$20.98, followed by Ontario at \$19.66; however, both Yukon and Northwest Territories have higher averages rates than any province. The province with the lowest average rate was Prince Edward Island with \$16.01. With regards to the years of experience the national average was around eight, the province with the most experienced nannies was Nova Scotia, while the least experienced was Newfoundland. Only 66 profiles received reviews from clients, and three of those profiles have been deleted since the time they were first retrieved. In total 70 reviews have been filled (counting profiles that received more than one), with a national average rating of 3.71. Users from Ontario are by far the most likely to receive a review and they have an average rating of 3.86, while users from BC had a very low average rating of 2.6. 
```{r fig.width=9, fig.height=6.5}
#| fig-cap: "Distribution of requested hourly rates by number of items listed under different subsections."
plot_from_lists <- function(df, factor_column, y_var, title = ""){
 temp_df <- df |> 
  group_by({{factor_column}}) |> 
  summarise(yloc = 55, 
            label = paste0(n()))

  df |> 
    ggplot(aes({{factor_column}}, {{y_var}}, fill = {{factor_column}})) + 
    geom_boxplot(show.legend = F) + 
    geom_text(data = temp_df, aes(y = yloc, label = label), 
              position = position_dodge(width = 0.75)) +
    theme_bw() + ggtitle(title) + ylim(c(10,60))
}

profiles_lists <- data |> 
  select(name, city, rate, years_exp, 
         availability_work, experience_ages, experience_conditions, 
         details_transport, qualifications_provide, qualifications_languages,
         services_responsabilities, link) |>
  unique() |> 
  filter(rate < 100) |> 
  mutate_at( vars(-all_of(c("name", "rate", "city", "years_exp", "link"))), 
             ~factor(ifelse(. == "" | is.na(.), 0 ,str_count(., ",") + 1))) |> 
  mutate(services_responsibilities = services_responsabilities)

p1 <- plot_from_lists(profiles_lists, availability_work, rate, title = "A")
p2 <- plot_from_lists(profiles_lists, experience_ages, rate, title = "B")
p3 <- plot_from_lists(profiles_lists, experience_conditions, rate, title = "C")
p4 <- plot_from_lists(profiles_lists, details_transport, rate, title = "D")
p5 <- plot_from_lists(profiles_lists, qualifications_provide, rate, title = "E")
p6 <- plot_from_lists(profiles_lists, services_responsibilities, rate, title = "F")

grid.arrange(p1,p2,p3,p4,p5,p6)
```
As mentioned before, each user describes on their profiles the services they are willing or qualified to provide. One thing worth exploring is how the requested hourly rate varies depending on the number of qualifications the nannies listed. Figure 1 shows the distribution of hourly rates by the number of items users wrote under those subsections. Above each boxplot, the number of users per category is shown. We can see that, except for the subsection of "responsibilities" under "Services," those who didn't have items listed under that subsection had the lowest median rate. However, the difference between distributions isn't significant enough to draw any conclusions just yet. Figure 2 shows the difference in rate distribution for users who reported being qualified to provide Cardiopulmonary resuscitation (CPR). We can see that those who can provide CPR tend to request a higher hourly rate on average.
```{r fig.width=4.5, fig.height=2.5, fig.align='center'}
#| fig-cap: "Distribution of hourly rates based on whether the user can provide CPR."
profiles_cpr <- data |> 
  select(name, city, rate, link, qualifications_provide) |> 
  unique() |> 
  mutate(CPR = factor(ifelse(grepl("CPR", qualifications_provide), "Yes", "No"))) |> 
  filter(rate < 100) 

plot_from_lists(profiles_cpr, CPR, rate)
```
## Exploratory Text Analysis
The profile descriptions of the users were highly similar to one another; all of them talked overwhelmingly positively about themselves, which isn't surprising since they are trying to establish trust with their possible employers. In a more in-depth text analysis, it was found that the users who had a negative sentiment score wrote a very short description and included phrases such as "don't hesitate to..." and most lexicons classify the word "hesitate" as negative. In Figure 3, we can see the most common words that appeared in the "About Me" section of the profiles. Unsurprisingly, the most common words were "children," "care," and "nanny."

```{r fig.width=4, fig.height=2.5, fig.align='center'}
#| fig-cap: "Proportion of appearance of words in the profile description (removing stop words)."
data |> 
  select(name, about_me, link) |> 
  unique() |> 
  unnest_tokens(word, about_me) |> 
  anti_join(stop_words, join_by(word)) |> 
  count(word) |> 
  mutate(prop = n/sum(n)) |> 
  slice_max(prop, n = 15) |> 
  mutate(word = reorder(word, prop)) |> 
  ggplot(aes(prop, word, fill = word)) +
  geom_col(show.legend = F, col ="black") +
  xlab("Proportions") + theme_bw() + 
  ylab("")
  
```
We are also interested in how words are related to each other; that is, what are the most common words that come before a specific word. In Figure 4, we can see an arrangement of words in a network, or "graph." This was done using the igraph and ggraph libraries [2-4]. Some of the most common bigram examples are "qualified/passionate/professional nanny," "pet care," "meal preparation," and "primary school." We can also see that the network detects the city and province the nannies are based in when they mention it in their descriptions, as well as, their hourly rate.
```{r}
bigram_graph <- data |> 
  select(name, about_me, link) |> 
  unique() |> 
  unnest_tokens(bigram, about_me, token = "ngrams", n = 2) |> 
  filter(!is.na(bigram)) |> 
  separate(bigram, c("word1", "word2"), sep = " ") |> 
  filter(!word1 %in% stop_words$word,
         !word2 %in% stop_words$word) |> 
  count(word1, word2, sort = T) |> 
  filter(n > 100) |> 
  graph_from_data_frame()

```
```{r fig.width=8, fig.height=5}
#| fig-cap: "Graph representation of bigrams in the profile descriptions (removing stop words)."
a <- grid::arrow(type = "closed", length = unit(.15, "inches"))
ggraph(bigram_graph, layout = "fr") +
  geom_edge_link(aes(edge_alpha = n), show.legend = FALSE, arrow = a,
                  end_cap = circle(.07, 'inches')) +
  geom_node_point(color = "lightblue", size = 4) +
  geom_node_text(aes(label = name), vjust = 1, hjust = 1, size = 3) +
  theme_void()
```
## Information Retrieval Approaches
Information Retrieval (IR) is the process of obtaining any type of media based on user information needs. The resulting IR system is often called a search engine [5]. The IR task that we consider returns a list of ordered sentences, taken from profile descriptions, based on a query. The IR architecture uses the vector representations of queries and sentences, which are then ordered based on a similarity function like cosine or dot product. 

### BM25Okapi
BM25 stands for "Best Matching 25" (i.e the 25th iteration of the function), and Okapi makes reference to the first IR system that used it. This is a bag-of-words model in which query and document vectors are based on unigram word counts, and each word is consider independently of its position. This function is similar to TF-IDF (term frequency - inverse document frequency) weighting, but it adds two parameters: $k$, which adjusts the balance between term frequency and IDF, and $b$, which controls the importance of document length normalization [5]. The BM25 score of a query $Q$ containing keywords $q_1,...,q_n$ and a document $D$ is:
$$
\text{score}(D,Q) = \sum_{i=1}^n\text{IDF}(q_i)\times\frac{tf(q_i, D)\ \cdot \ (k+1)}{tf(q_1, D)+k\times\left(1-b+\frac{b \ |D|}{|D|_{\text{avg}}}\right)}
$$
Where $tf(q_i, D)$ is the number of times the keyword $q_i$ appears on document $D$, $|D|$ is the length of the document and $|D|_{\text{avg}}$ is the average document length. The inverse document frequency $\text{IDF}(q_i)$ is often computed as:
$$
\text{IDF}(q_i)=\log\left(\frac{N-n(q_i)+0.5}{n(q_i)+0.5}+1\right)
$$
Where $N$ is the total number of documents and $n(q_i)$ is the number of documents containing the keyword $q_i$. To implement this method we are using the python package `rank_bm25` which sets $k=1.5$ and $b=0.75$ by default [6]. It also sets keywords with negative IDF to the average of the non-negative IDFs multiply by 0.25. 
In various IR tasks is common to remove "stop words" from the text, because these words carry little semantic knowledge and they often hurt the process. However, it's not strictly necessary since the IDF downweights these stop words.  
```{r}
df <- data.frame(Cat = c("BM25", "multi-qa-mpnet"), 
                 Query = linebreak(c("Do you need sponsorship?\nimmigration visa sponsor sponsorship", 
                                     "Do you need sponsorship?\nimmigration visa sponsor sponsorship"), align = "l"), 
                 Threshold = linebreak(c("5.0\n0.0", "0.4\n0.4"), align = "c"), 
                 total_users = linebreak(c("248\n213", "198\n97"), align = "c"), 
                 true_positives = linebreak(c("84\n183", "87\n84"), align = "c"))

kable(df, col.names = c("Model", "Query", "Threshold", "Total Users Retrieved", "True Positives"), booktabs = T, 
      escape = F, caption = "Users that requiere visa sponsorship retrieved by IR models.", align = "c") |> 
  kable_styling( latex_options = "hold_position")
```
The fatal flaw of the BM25 scoring function is that the query's keywords have to appear in the documents that it's searching through. So if the author used a synonym or expressed it in another way the model has no way of knowing that that is a relevant document. An additional disadvantage is that it doesn't take into account how close the keywords are together in the document, in our application we are dividing the profile descriptions by sentence, so the proximity between words shouldn't be an important issue. 

### Sentence Embeddings
Our second approach was to compute vector representations of sentences, or embeddings using transformer models. We used the `SentenceTransformers` package in python, which was developed for semantic search tasks just like this one, for a full explanation of the models used in this package we refer the users to the original Sentence-BERT paper [7]. Basically these models work by "masking" a word from the sentence and using the context both before and after this word (bidirectional) to predict it. Given that BERT (Bidirectional Encoder Representations from Transformers) is quite large and therefore computationally expensive, we didn't use it to encode our sentences. In contrast, we mainly used the `multi-qa-mpnet-base` bi-encoder model, which was specifically trained on 215 million question-answer pairs from sources such as yahoo answers, StackExchange and Google and Bing search queries, making it a perfect match for our use case. Once the embeddings of both the query and sentences are computed we can use the cosine or dot product similarity score to ranked them.

The main advantage of this approach is that we don't need to have the query keywords appear on the sentences, the model should retrieve sentences that don't contain any of the words but have synonyms or similar ones. This could be both an advantage and disadvantage, however, because the model might select certain sentences that although are similar, aren't really relevant for that specific query. For example, when feeding the query "Do you need visa sponsorship?", the model would selected sentences such as: "I have a driver's license", one can claim that a visa and a driver's license are similar but the latter isn't really relevant for our goal. 
```{r}
bm25_sponsor_question <- read.csv("../data/output/python_tests/bm25/sponsor_results_2023-09-04.csv")
bm25_sponsor_keywords <- read.csv("../data/output/python_tests/bm25/sponsor_results_alt_query_2023-09-04.csv")
st_sponsor_question <- read.csv('../data/output/python_tests/multi-qa-mpnet-base-cos-v1/sponsor_results_2023-09-04.csv')
st_sponsor_keywords <- read.csv('../data/output/python_tests/multi-qa-mpnet-base-cos-v1/sponsor_results_alt_query_2023-09-04.csv')

bm25_age_keywords <- read.csv("../data/output/python_tests/bm25/user_ages_2023-09-04.csv")
bm25_age_question <- read.csv("../data/output/python_tests/bm25/user_ages_query_alt_2023-09-04.csv")
st_age_keywords <- read.csv('../data/output/python_tests/multi-qa-mpnet-base-cos-v1/user_ages_2023-09-04.csv')
st_age_question <- read.csv('../data/output/python_tests/multi-qa-mpnet-base-cos-v1/user_ages_query_alt_2023-09-04.csv')

bm25_country_keywords <- read.csv("../data/output/python_tests/bm25/countries_2023-09-04.csv")
bm25_country_question <- read.csv("../data/output/python_tests/bm25/countries_query_alt_2023-09-04.csv")
st_country_keywords <- read.csv('../data/output/python_tests/multi-qa-mpnet-base-cos-v1/countries_2023-09-04.csv')
st_country_question <- read.csv('../data/output/python_tests/multi-qa-mpnet-base-cos-v1/countries_query_alt_2023-09-04.csv')
```
### Information retrieved
We were interested in retrieving demographic variables of the user, like age and nationality, as well as, their immigration status in Canada and if they require sponsorship. All these variables were retrieved using both approaches described above. For all of these the top 1k sentences were obtained then select the one with the maximum score per distinct profile. For the age variable, we used regular expression to extract numbers within the text, then we removed those younger than 14 and older than 100 years and those with reported years of experience + 10 higher than their age, since these are most likely mistakes. For the countries we used a list of country names and their adjectival and demonymic forms retrieved from wikipedia [8]. For the sponsorship arbitrary score thresholds were selected, then manually label the resulting sentences. 
```{r fig.height=3.2, fig.width=10}
#| fig-cap: Distribution of years of experience and hourly rate of users based on visa requierements.

data_labeled <- data |> 
  left_join(bm25_sponsor_keywords |> select(link, sponsor), join_by(link)) |> 
  mutate(sponsor = factor(ifelse(is.na(sponsor), 0, 1))) |> 
  left_join(bm25_age_keywords |> select(link, age), join_by(link)) |> 
  mutate(age = ifelse(years_exp + 10 > age, NA, age)) |> 
  left_join(st_country_keywords |> select(link, country), join_by(link))

p1 <- data_labeled |> 
  ggplot(aes(sponsor, years_exp, fill = sponsor)) + geom_boxplot(show.legend = F) + 
  ylim(c(10, 60)) + theme_bw() + xlab("Needs Sponsorship") + ylab("") + 
  ggtitle("Experience (years)") + scale_y_continuous(breaks = seq(0,60,5), limit = c(0,55))

p2 <- data_labeled |> 
  ggplot(aes(sponsor, rate, fill = sponsor)) + geom_boxplot(show.legend = F) + 
  theme_bw() + xlab("Needs Sponsorship") + ylab("") + 
  ggtitle("Hourly rate (CAD)") + scale_y_continuous(breaks = seq(10,60,5), limit = c(10,60))

p3 <- data_labeled |> 
  ggplot(aes(sponsor, age, fill = sponsor)) + geom_boxplot(show.legend = F) +
  ylim(c(10, 60)) + theme_bw() + xlab("Needs Sponsorship") + ylab("") + 
  ggtitle("Age (years)")+ scale_y_continuous(breaks = seq(15,65,5), limit = c(15,65))
  
  
grid.arrange(p1,p2, p3, ncol = 3)
```
## Results
### Immigration status
All three variables were extracted with both approaches and two different queries: a keyword-based query and a question. With regards to retrieving users who needed sponsorship table 2 shows the queries and thresholds used, as well as, the number of users and true positives (users who actually required sponsorship as reviewed manually afterwards) retrieved. The BM25 model, with the keyword-based query, retrieved the most true positives from the texts; even though, the bi-encoder model had a better ratio of true positives, it's unclear if this holds when reducing the threshold to allow the retrieval of more users. Therefore, we consider that the BM25 model is the most appropriate for this specific task.
```{r include = FALSE}
table(bm25_sponsor_question$sponsor)
table(bm25_sponsor_keywords$sponsor)
table(st_sponsor_question$sponsor)
table(st_sponsor_keywords$sponsor)
```
```{r}
#| fig-cap: Number and proportion of users who require sponsorship by province or territory.
p1 <- data_labeled |> 
  distinct(link, .keep_all = T) |> 
  filter(sponsor == 1) |> 
  count(province) |> 
  ungroup() |>
  arrange(n) |>
  mutate(province = factor(province, levels=province)) |> 
  ggplot(aes(n, province, fill = province)) + 
  geom_col(show.legend = F) + theme_bw() +
  geom_text(aes(label = n)) + 
  xlab("Users who require sponsorship") + ylab("") 

p2 <- data_labeled |> 
  distinct(link, .keep_all = T) |> 
  group_by(province) |> 
  summarise(immigrant_prop = mean(as.numeric(sponsor) == 2), 
            count = n(), 
            immigrant_count = sum(as.numeric(sponsor) == 2)) |> 
  mutate(province = reorder(province, immigrant_count)) |> 
  filter( immigrant_prop < 0.3) |> filter( immigrant_prop > 0) |> 
  ggplot(aes( immigrant_prop, province, fill = province)) + 
  geom_col(show.legend = F) + 
  geom_text(aes(label=round(immigrant_prop, 3))) + 
  ylab("") + xlab("Proportion of immigrant users") + 
  theme_bw() + theme(axis.text.y=element_text())

grid.arrange(p1, p2, ncol = 2)
```
As we can see in figure 5 users who need to be sponsored are willing to charge a slightly lower rate than those who doesn't. The distribution of reported years of experience of nannies who require sponsorship is much less spread out than those who doesn't. Figure 6 shows the number and proportion of users requesting sponsorship by province, unsurprisingly Ontario has the most foreign users, however, the Yukon territory has by far the highest proportion, where 2 out of 11 users where found to be looking for sponsorship. 
```{r}
#| fig-cap: Age distribution of users and by province (selecting those with at least 2 users with valid ages).

p1 <- data_labeled |> ggplot(aes(age, y=..density..)) + 
  geom_histogram(col="black", fill="steelblue3") + 
  geom_density(alpha = 0.2, fill="black") + 
  geom_vline(xintercept = median(data_labeled$age, na.rm = T), linetype="dashed", 
             linewidth=0.7, col="darkgray") + 
  theme_bw() + 
  ggtitle("Distribution over all users") + ylab("") + scale_x_continuous(breaks = seq(10, 70, 5)) + 
  xlab("Age")
 
p2 <- data_labeled |> 
   filter(!province %in% c(NA, " Yukon", " Unorganized", 
                           " Newfoundland and Labrador", " Northwest Territories",
                           " Prince Edward Island", " New Brunswick")) |> 
   ggplot(aes( age, province, fill = province)) + geom_boxplot(show.legend = F) +
   scale_x_continuous(breaks = seq(10, 70, 5)) + theme_bw() + 
  ylab("") + xlab("Age") + ggtitle("Distribution by province")

grid.arrange(p1, p2, ncol = 2)
```
### Users' age
For this task we used the queries: "How old are you?" and "I am years old". There was no need to select a threshold when retrieving users' age, since out of the top sentences we just extract the numbers and performed the subsequent transformations mentioned before. The BM25 with the keyword-based query was able to retrieve 237  users with apparent valid ages and 223 with the question based one, while the bi-encoder performed better with the question query it only manage to extract 195 users with valid ages. Important to note that the entries haven't been double checked manually.
```{r include=FALSE}
#data_labeled |> left_join(bm25_age_question |> select(link, age), join_by(link)) |> 
#  mutate(age = ifelse(years_exp + 10 > age, NA, age)) |> select(age) |> 
#  pull() |> is.na() |> table()
#data_labeled |> left_join(bm25_age_keywords |> select(link, age), join_by(link)) |> 
#  mutate(age = ifelse(years_exp + 10 > age, NA, age)) |> select(age) |> 
#  pull() |> is.na() |> table()
#data_labeled |> left_join(st_age_question |> select(link, age), join_by(link)) |> 
#  mutate(age = ifelse(years_exp + 10 > age, NA, age)) |> select(age) |> 
#  pull() |> is.na() |> table()
#data_labeled |> left_join(st_age_keywords |> select(link, age), join_by(link)) |> 
#  mutate(age = ifelse(years_exp + 10 > age, NA, age)) |> select(age) |> 
#  pull() |> is.na() |> table()
print("Before trans")
table(is.na(bm25_age_question$age))
table(is.na(bm25_age_keywords$age))
table(is.na(st_age_question$age))
table(is.na(st_age_keywords$age))
```
Figure 7 shows the distribution of age over all users and by province. The median over the whole population is 25, and the provinces' median ranges from 20 to 25 years old. It's clear that the distributions of the total users and for each provinces are right-skewed. There were only 6 users requesting to be sponsored with valid ages, in figure 5 we can see that there's a substantial difference between the ages of this group and locals. While users who are able to work legally in Canada have a median age very similar to the total at 25 years, nannies who want to immigrate to Canada are on average 32 years old; however, more data is needed to claim that there's a significant difference.

### Nationalities
The two queries we tested with in order to retrieve users' country or nationality were: "I am from" and "Where are you from?". However, almost every word in these queries are included in the stop words lexicon that we are using before feeding the queries into the BM25 model, so it's not able to retrieve any valid sentence (future iterations will not remove stop words from the text so a proper comparison will be made). The transformer model is able to retrieve 243 users with valid nationalities using the keyword-based query. 

The majority of foreign users (78) are originally from the Philippines, followed by Mexico with 21 users. Figure 8 shows the differences in rate distribution and reported years of experience by country of origin. Nannies from the Philippines are willing to take a substantially lower pay than others, with a median hourly rate of less than \$16 CAD and some users even going down to \$12 per hour. Users from Mexico, Japan, Colombia or Brazil have an hourly rate much closer to the global median at \$20 an hour.
```{r include=FALSE}
table(st_country_keywords$country != "Canada")
table(st_country_question$country != "Canada")
```

```{r}
#| fig-cap: Age distribution of users and by province (selecting those with at least 2 users with valid ages).
p1 <- data_labeled |> 
  count(country) |> 
  filter(!country %in% c("Canada", "United States of America"), 
         !is.na(country), n > 3) |> 
  ungroup() |>
  arrange(n) |>
  mutate(country = factor(country, levels=country)) |> 
  ggplot(aes(n, country, fill = country)) + 
  geom_col(show.legend = F) + theme_bw() +
  geom_text(aes(label = n)) + 
  xlab("Users") + ylab("") 

p2 <- data_labeled |> 
  group_by(country) |> 
  mutate(n = n()) |> 
  ungroup() |> 
  mutate(country = reorder(country, n)) |> 
  filter(!country %in% c("Canada", "United States of America"), 
         !is.na(country), n > 3) |> 
  ggplot(aes( rate, country, fill = country)) + geom_boxplot(show.legend = F) + 
  theme_bw() + ylab("") + xlab("Rate (CAD)") +
  scale_x_continuous(breaks = seq(4.0,40.0,4), limits = c(11,38)) +
  theme(axis.text.y = element_blank())

p3 <- data_labeled |> 
  group_by(country) |> 
  mutate(n = n()) |> 
  ungroup() |> 
  mutate(country = reorder(country, n)) |> 
  filter(!country %in% c("Canada", "United States of America"), 
         !is.na(country), n > 3) |> 
  ggplot(aes( years_exp, country, fill = country)) + geom_boxplot(show.legend = F) + 
  theme_bw() + ylab("") + xlab("Experience (years)") +
  theme(axis.text.y = element_blank())

grid.arrange(p1, p2, p3, ncol = 3)
  
```
## Conclusion
In this report we analyzed profile descriptions of nannies across Canada and extracted demographic variables from the text descriptions using information retrieval techniques with two different approaches: a lexical keyword-based algorithm (BM25) and calculating sentence embeddings with transformer models. Both approaches were able to extract meaningful insights from the data, but the BM25 function was able to retrieve  more information with respect to the immigration status and age variables. This shows that deterministic models are still highly valuable in certain IR tasks.

We were able to extract 183 users, using BM25 scoring, not authorized to work in Canada who are asking for visa sponsorship, we didn't take into account immigrants who mentioned having a work visa, we also didn't make a distinction between users asking for sponsorship from outside or inside the country. It's clear that these nannies are willing to charge a lower hourly rate than those with a regular immigration status and their age was significantly higher than the average age of the local nannies. There weren't substantial differences with regards to their experience or qualifications. Around 230 users mentioned being born in a foreign country, the vast majority of these were from the Philippines, which is in accordance with current immigration trends in Canada. In future iterations of the project we would like to look at analyze all immigrants as a whole and compare them to the local workforce, as well as, analyzing users by gender and by their profile picture with image processing techniques. 

## References
[1] CareGuide: CanadianNanny.ca. Retrieved July 3, 2023 from: https://canadiannanny.ca/nannies/ontario.

[2] Silge, J., &; Robinson, D. (2017). Text mining with R: A tidy approach. O’Reilly. 

[3] Pedersen T (2022). ggraph: An Implementation of Grammar of Graphics for Graphs and Networks. https://ggraph.data-imaginist.com, https://github.com/thomasp85/ggraph. 

[4] Csardi G, Nepusz T (2006). “The igraph software package for complex network research.” InterJournal, Complex Systems, 1695. https://igraph.org.

[5] Jurafsky, D., &amp; Martin, J. H. (2022). Speech and language processing: An introduction to natural language processing, computational linguistics, and speech recognition. Pearson. 

[6] Dorian Brown. (2020). Rank-BM25: A Collection of BM25 Algorithms in Python.

[7] Reimers, N., & Gurevych, I. (2019). Sentence-BERT: Sentence Embeddings using Siamese BERT-Networks. In Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing. Association for Computational Linguistics.

[8] List of adjectival and demonymic forms for countries and nations. Wikipedia. Retrieved September 8th, 2023 from: https://en.wikipedia.org/wiki/List_of_adjectival_and_demonymic_forms_for_countries_and_nations.
