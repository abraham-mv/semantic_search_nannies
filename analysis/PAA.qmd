---
title: "Using web data to study the informal childcare sector in Canada"
author:
  - name: Jose Morales Vidales 
  - name: Monica Alexander 
subtitle: "Abstract submitted to PAA 2024"
format: pdf
number-sections: true
abstract: " add abstract here"
fontsize: 11pt
linestretch: 1.5
execute:
  echo: false
  warning: false
  message: false
  include: true
---

```{r}
library(tidyverse)
library(gridExtra)
library(kableExtra)
library(knitr)
library(tidytext)
library(igraph)
library(ggraph)
```


```{r}
data <- read.csv("../data/input/nannies_profiles_canada.csv") |> 
  mutate(date = as.Date(date)) |> 
  filter(date < as.Date("2023-09-05")) |> 
  arrange(desc(date)) |> 
  distinct(link, .keep_all = T) |> 
  mutate(across(c(rate, years_exp, experience_children, num_reviews), 
                ~as.numeric(str_extract(., "\\d+(?:\\.\\d+)?"))),
         star_rating = ifelse(is.na(num_reviews), NA, star_rating), 
         num_reviews = ifelse(is.na(num_reviews), 0, num_reviews), 
         province = trimws(province, "left"))

bm25_sponsor_question <- read.csv("../data/output/python_tests/bm25/sponsor_results_2023-09-04.csv")
bm25_sponsor_keywords <- read.csv("../data/output/python_tests/bm25/sponsor_results_alt_query_2023-09-04.csv")
st_sponsor_question <- read.csv('../data/output/python_tests/multi-qa-mpnet-base-cos-v1/sponsor_results_2023-09-04.csv')
st_sponsor_keywords <- read.csv('../data/output/python_tests/multi-qa-mpnet-base-cos-v1/sponsor_results_alt_query_2023-09-04.csv')

bm25_age_keywords <- read.csv("../data/output/python_tests/bm25/user_ages_2023-09-04.csv")
bm25_age_question <- read.csv("../data/output/python_tests/bm25/user_ages_query_alt_2023-09-04.csv")
st_age_keywords <- read.csv('../data/output/python_tests/multi-qa-mpnet-base-cos-v1/user_ages_2023-09-04.csv')
st_age_question <- read.csv('../data/output/python_tests/multi-qa-mpnet-base-cos-v1/user_ages_query_alt_2023-09-04.csv')

bm25_country_keywords <- read.csv("../data/output/python_tests/bm25/countries_2023-09-04.csv")
bm25_country_question <- read.csv("../data/output/python_tests/bm25/countries_query_alt_2023-09-04.csv")
st_country_keywords <- read.csv('../data/output/python_tests/multi-qa-mpnet-base-cos-v1/countries_2023-09-04.csv')
st_country_question <- read.csv('../data/output/python_tests/multi-qa-mpnet-base-cos-v1/countries_query_alt_2023-09-04.csv')

data_labeled <- data |> 
  left_join(bm25_sponsor_keywords |> select(link, sponsor), join_by(link)) |> 
  mutate(sponsor = factor(ifelse(is.na(sponsor), 0, 1))) |> 
  left_join(bm25_age_keywords |> select(link, age), join_by(link)) |> 
  mutate(age = ifelse(years_exp + 10 > age, NA, age)) |> 
  left_join(st_country_keywords |> select(link, country), join_by(link))
```


# Introduction and motivation

Demand for non-parental childcare has increased substantially in recent decades, largely driven by an increase in labour force participation of women. In Canada, the use of non-parental childcare covered more than half of families in 2022 (REF). As well as centre-based and licensed or regulated childcare providers, an important part of the childcare landscape in Canada is unlicensed home-based childcare, provided by baby-sitters and nannies. Demand for this informal home-based childcare has also recently increased, potentially because of the relative flexibility of hours compared to childcare centres, and in response to health concerns surrounding the Covid-19 pandemic (REF). Compared to employees in regulated childcare options, nannies may experience less job security, more uncertainty, and poorer working conditions (REF). 

Despite the increasing importance of workers in the informal childcare sector in countries such as Canada, little is known about the characteristics, working conditions, and employment outcomes of this sub-population. Data collected in censuses and surveys is limited; informal childcare workers are often hard to distinguish between care-workers in general, and information about working conditions and place of work is also limited. In Canada, in 2022 there was a survey on the provision of childcare services, but the focus of this study was largely on formal childcare services, in response to national-level changes in childcare subsidies (REF).

As such, in this project we utilize a large, rich, dataset constructed from public web profiles on a nanny advertising website to better understand the characteristics and systematic inequalities in the informal childcare sector in Canada. We are particularly interested in studying differences in work expectations and outcomes by country of birth and migrant status. We extracted almost 10,000 unique online profiles over three months from the website canadiannanny.ca. These profiles contain a range of different types of information, including advertised pay rate, qualifications, experience, as well as a free-text biography. We then used a variety of text-based methods to extract information on key demographic characteristics, including country of origin, age, and citizenship status. 

In the remainder of this abstract, we describe the data extraction process, methods used to retrieve information on demographic characteristics, initial results and future work. 

# Data 

We obtained information on characteristics of nannies seeking work in Canada from the website canadiannanny.ca. This website, which is used by over 200,000 potential nannies across Canada, contains incredibly rich data on nannies’ characteristics and experiences on their profiles (example below XX ADD SCREENSHOT OF PROFILE).
    
We used webscraping tools in R (primarily relying on the `rvest` package) to extract information on nannies from publicly available profiles. The profiles were scraped using an R script at multiple points of July, August and September 2023. They were retrieved in order of appearance on the site which is sorted by the last time the user was active on the platform. So far more than 16,000 entries have been scraped from the site, of those around 9,700 are distinct users. 
![Profile example.](figures/profile_example.png){width=60%}

Demographic variables are usually reported by the user in the text-based sections of their profiles, which include the short blurb right under the profile picture, a "Reasons to Hire Me" section, and a longer description in the "About Me" section. We also retrieved the users' name, url, location, reported years of experience, hourly rate, last time active on the site, number of reviews, star rating out of five, bullet points under the "I can work:" subsection (part-time, full-time, summer, etc.), children ages the user has experience with (infant, toddler, newborn, etc.), number of children they can look after, experience with children with medical conditions (diabetes, disability, epilepsy, severe allergies, etc.), transportation requirements (close to transit, has driver's license, etc.), qualifications (first aid, CPR, languages, etc.), and services they can provide (housekeeping, cooking, groceries, swim supervision, etc.).

# Retrieving demographic characteristics from profiles

In this project we are interested in studying differences in user information by key demographic characteristics, particularly age, migrant status (in particular, if the user requires sponsorship), and country of origin. However, these characteristics are not reported in profiles in a fixed field, but rather the information is often contained somewhere in the free-text user-written biographies (XX TODO ADD EXAMPLE TEXT). As such, in order to retrieve the information of interest, we use several information retrieval approaches. 

::: {.callout-tip appearance="minimal"}
## Free-text biography example.
Hi there, my name is Erin (she/her), (23 years old)! 

I am a recent (2022) graduate from the University of Waterloo with an Honours degree in Therapeutic Recreation.  I spent four years nannying for two families (that I connected with on this website), while completing my degree. 

I moved to Toronto in the Fall of 2022 and reside in the West End, Roncesvalles neighbourhood. I have nannied for two families since being in Toronto, one who I am currently working with, and can connect you with both past and present families for recommendations! 
...
:::

Information Retrieval (IR) is the process of obtaining any type of media based on user information needs. The resulting IR system is often called a search engine (REF). The IR task that we consider returns a list of ordered sentences, taken from profile descriptions, based on a query. The IR architecture uses the vector representations of queries and sentences, which are then ordered based on a similarity function like cosine or dot product. We tested two main IR methods to extract demographic information of interest. Below is a brief description of both methods considered. 

## BM25Okapi
BM25 stands for "Best Matching 25" (i.e the 25th iteration of the function), and Okapi makes reference to the first IR system that used it. This is a bag-of-words model in which query and document vectors are based on unigram word counts, and each word is considered independently of its position. This function is similar to TF-IDF (term frequency - inverse document frequency) weighting, but it adds two parameters: $k$, which adjusts the balance between term frequency and IDF, and $b$, which controls the importance of document length normalization (REF). The BM25 score of a query $Q$ containing keywords $q_1,...,q_n$ and a document $D$ is:
$$
\text{score}(D,Q) = \sum_{i=1}^n\text{IDF}(q_i)\times\frac{tf(q_i, D)\ \cdot \ (k+1)}{tf(q_1, D)+k\times\left(1-b+\frac{b \ |D|}{|D|_{\text{avg}}}\right)}
$$
Where $tf(q_i, D)$ is the number of times the keyword $q_i$ appears on document $D$, $|D|$ is the length of the document and $|D|_{\text{avg}}$ is the average document length. The inverse document frequency $\text{IDF}(q_i)$ is often computed as:
$$
\text{IDF}(q_i)=\log\left(\frac{N-n(q_i)+0.5}{n(q_i)+0.5}+1\right)
$$
Where $N$ is the total number of documents and $n(q_i)$ is the number of documents containing the keyword $q_i$. To implement this method we are using the python package `rank_bm25` which sets $k=1.5$ and $b=0.75$ by default (REF). It also sets keywords with negative IDF to the average of the non-negative IDFs multiply by 0.25. In various IR tasks is common to remove "stop words" from the text, because these words carry little semantic knowledge and they often hurt the process. However, it's not strictly necessary since the IDF downweights these stop words.  

A major disadvantage of the BM25 scoring function is that the query's keywords have to appear in the documents that it's searching through. So if the author used a synonym or expressed it in another way the model has no way of knowing that that is a relevant document. An additional disadvantage is that it doesn't take into account how close the keywords are together in the document. In our application we are dividing the profile descriptions by sentence, so the proximity between words shouldn't be an important issue. 

## Sentence Embeddings
Our second approach was to compute vector representations of sentences, or embeddings using transformer models. We used the `SentenceTransformers` package in python, which was developed for semantic search tasks similar to our goal here (REF). We mainly used the `multi-qa-mpnet-base` bi-encoder model, which was specifically trained on 215 million question-answer pairs from sources such as Yahoo answers, StackExchange and Google and Bing search queries. Once the embeddings of both the query and sentences are computed we can use the cosine or dot product similarity score to rank them.

The main advantage of this approach is that we don't need to have the query keywords appear on the sentences; the model should retrieve sentences that don't contain any of the words but have synonyms or similar ones. This could be both an advantage and disadvantage, however, because the model might select certain sentences that although are similar, aren't really relevant for that specific query. For example, when feeding the query "Do you need visa sponsorship?", the model would selected sentences such as: "I have a driver's license". 

## Queries used and retrieval results

### Immigration Status

All three variables were extracted with both approaches and two different queries: a keyword-based query and a question. With regards to retrieving users who needed sponsorship, Table 1 shows the queries and thresholds used, as well as, the number of users and true positives (users who actually required sponsorship as reviewed manually afterwards) retrieved. The BM25 model, with the keyword-based query, retrieved the most true positives from the texts; even though, the bi-encoder model had a better ratio of true positives, it's unclear if this holds when reducing the threshold to allow the retrieval of more users. Therefore, we consider that the BM25 model is the most appropriate for this specific task.
<!--XX INSERT TABLE-->
```{r align="center"}
df <- data.frame(Cat = c("BM25", "multi-qa-mpnet"), 
                 Query = linebreak(c("Do you need sponsorship?\nimmigration visa sponsor sponsorship", 
                                     "Do you need sponsorship?\nimmigration visa sponsor sponsorship"), align = "l"), 
                 Threshold = linebreak(c("5.0\n0.0", "0.4\n0.4"), align = "c"), 
                 total_users = linebreak(c("248\n213", "198\n97"), align = "c"), 
                 true_positives = linebreak(c("84\n183", "87\n84"), align = "c"))

kable(df, col.names = c("Model", "Query", "Threshold", "Total Users Retrieved", "True Positives"), booktabs = T, 
      escape = F, caption = "Users that requiere visa sponsorship retrieved by IR models.", align = "c") |> 
  kable_styling( latex_options = "hold_position", position = "center")
```


### Country of origin

The two queries we tested with in order to retrieve users' country or nationality were: "I am from" and "Where are you from?". However, almost every word in these queries are included in the stop words lexicon that we are using before feeding the queries into the BM25 model, so it's not able to retrieve any valid sentence (future iterations will not remove stop words from the text so a proper comparison will be made). The transformer model is able to retrieve 243 users with valid nationalities using the keyword-based query. 


### Age

For this task we used the queries: "How old are you?" and "I am years old". There was no need to select a threshold when retrieving users' age, since out of the top sentences we just extract the numbers and performed the subsequent transformations mentioned before. The BM25 with the keyword-based query was able to retrieve 237 users with apparent valid ages and 223 with the question based one, while the bi-encoder performed better with the question query it only manage to extract 195 users with valid ages. 


# Initial results and observations

## Summary characteristics by province and age

```{r align="center"}
territories <- c("Yukon", "Northwest Territories", "Nunavut")
data_labeled |> 
  filter(!is.na(province), 
         province != "Unorganized") |> 
  mutate(province = ifelse(province %in% territories, "Territories", province)) |> 
  group_by(province) |> 
  summarise(`N (prop.)` = paste0(n(), 
                      " (", round(n()/dim(data)[1], 2), ")"), 
            `Rate (sd)` = paste0(round(mean(rate[rate < 200], na.rm = T), 2), 
                               " (", round(sd(rate[rate < 200], na.rm=T), 2), ")"), 
            `Years Ex. (sd)` = paste0(round(mean(years_exp[years_exp < 50], na.rm = T), 2), 
                               " (", round(sd(years_exp[years_exp < 50], na.rm=T), 2), ")"),
            `No. Children (sd)` = paste0(round(mean(experience_children, na.rm = T), 2), 
                               " (", round(sd(experience_children, na.rm=T), 2), ")"), 
            `Age (sd)` = paste0(round(mean(age, na.rm = T), 2), 
                               " (", round(sd(age, na.rm = T), 2), ")")) |>
  add_row(province = "National", 
          `N (prop.)` = paste0(dim(data)[1], " (",1.000, ")"), 
          `Rate (sd)` = paste0(round(mean(data$rate[data$rate < 200], na.rm = T), 2), 
                              " (", round(sd(data$rate[data$rate < 200], na.rm=T), 2), ")"), 
          `Years Ex. (sd)` = paste0(round(mean(data$years_exp[data$years_exp < 50], na.rm = T), 2), 
                             " (", round(sd(data$years_exp[data$years_exp < 50], na.rm=T), 2), ")"),
          `No. Children (sd)` = paste0(round(mean(data$experience_children, na.rm = T), 2), 
                             " (", round(sd(data$experience_children, na.rm=T), 2), ")"), 
          `Age (sd)` = paste0(round(mean(data_labeled$age, na.rm = T), 2), 
                               " (", round(sd(data_labeled$age, na.rm = T), 2), ")")) |>
  rename(`Province` = province) |> 
  kable(format="latex", booktabs = T, caption = "Average value of quantitative variables by province. The statistic in parenthesis is specified in the header.", digits = 3) |>
  kable_styling(full_width = F, latex_options = "hold_position", position = "center") |> 
  row_spec(11, hline_after = T) |> 
  column_spec(1, width = "2.7cm")
```

Table 2 shows summary statistics by province of specific characteristics reported by users. Ontario is by far the province with the most users with over 50% of these located there, followed by Alberta and British Columbia, which are both well over 1k users and above 15% of the total. At the national we have a mean hourly rate of \$19.51 CAD with a standard deviation of \$4.65, the province with highest rate in average was British Columbia with \$20.98, followed by Ontario at \$19.66; however, both Yukon and Northwest Territories have higher averages rates than any province. The province with the lowest average rate was Prince Edward Island with \$16.01. With regards to the years of experience the national average was around eight, the province with the most experienced nannies was Nova Scotia, while the least experienced was Newfoundland. 
<!--XX TODO Combine Yukon and Northwest Territories-->
```{r fig.width = 10, fig.height = 4}
#| fig-cap: Age distribution of users and by province (selecting those with at least 2 users with valid ages).

p1 <- data_labeled |> ggplot(aes(age, y=..density..)) + 
  geom_histogram(col="black", fill="steelblue3") + 
  geom_density(alpha = 0.2, fill="black") + 
  geom_vline(xintercept = median(data_labeled$age, na.rm = T), linetype="dashed", 
             linewidth=0.7, col="darkgray") + 
  theme_bw() + 
  ggtitle("Distribution over all users") + ylab("") + scale_x_continuous(breaks = seq(10, 70, 5)) + 
  xlab("Age")
 
p2 <- data_labeled |> 
  filter(!province %in% c(NA, "Yukon", "Unorganized", 
                           "Newfoundland and Labrador", "Northwest Territories",
                           "Prince Edward Island", "New Brunswick"), 
         !is.na(age)) |> 
  group_by(province) |> 
  mutate( province = paste0(province, "\n n = ", n())) |> 
  ungroup() |> 
  ggplot(aes( age, province, fill = province)) + 
  geom_violin( width = 1.1, alpha = 0.8) + 
  geom_boxplot(alpha=0.2, width = 0.2, fill = "black") + 
  theme_bw() +
  theme(legend.position="none") + 
  xlab("Age") + ylab("") + 
  scale_x_continuous(breaks = seq(10, 70, 5))

grid.arrange(p1, p2, ncol = 2, widths  = c(1.5, 1.8))
```
Only 66 profiles received reviews from clients, and three of those profiles have been deleted since the time they were first retrieved. In total 70 reviews have been filled (counting profiles that received more than one), with a national average rating of 3.71. Users from Ontario are by far the most likely to receive a review and they have an average rating of 3.86, while users from BC had a very low average rating of 2.6.

Figure 1 shows the distribution of age over all users and by province. The median over the whole population is 25, and the provinces' median ranges from 20 to 25 years old. It's clear that the distributions of the total users and for each provinces are right-skewed.

```{r}
data_sponsor <- data_labeled |> filter(sponsor == 1)
data_no_sponsor <- data_labeled |> filter(sponsor == 0)
data.frame( variable = c("Rate", "Years Exp.", "Age", "No. Children"),
            Mean = c( 
                  mean(data_sponsor$rate[data_sponsor$rate < 200], na.rm = T), 
                  mean(data_sponsor$years_exp[data_sponsor$years_exp < 50], na.rm = T), 
                  mean(data_sponsor$age, na.rm = T), 
                  mean(data_sponsor$experience_children, na.rm = T)), 
           `Std. dev.` = c(
                  sd(data_sponsor$rate[data_sponsor$rate < 200], na.rm = T), 
                  sd(data_sponsor$years_exp[data_sponsor$years_exp < 50], na.rm = T),  
                  sd(data_sponsor$age, na.rm = T), 
                  sd(data_sponsor$experience_children, na.rm = T)), 
           `Mean` = c( 
                  mean(data_no_sponsor$rate[data_no_sponsor$rate < 200], na.rm = T), 
                  mean(data_no_sponsor$years_exp[data_no_sponsor$years_exp < 50], na.rm = T), 
                  mean(data_no_sponsor$age, na.rm = T), 
                  mean(data_no_sponsor$experience_children, na.rm = T)),
           `Std. dev.` = c( 
                  sd(data_no_sponsor$rate[data_no_sponsor$rate < 200], na.rm = T), 
                  sd(data_no_sponsor$years_exp[data_no_sponsor$years_exp < 50], na.rm = T), 
                  sd(data_no_sponsor$age, na.rm = T), 
                  sd(data_no_sponsor$experience_children, na.rm = T))
                ) |> 
  kable(format="latex", booktabs = T, caption = "Statistics by immigrant status.", 
        col.names = c("", "Mean", "Std dev.", "Mean", "Std dev."), digits = 3) |>
  kable_styling(full_width = F, latex_options = "hold_position", position = "center") |> 
  add_header_above(c(" "=1, "Sponsorship" = 2, "No sponsorship" = 2))
```

## Nannies needing sponsorship

Table 3 users who need to be sponsored are willing to charge a slightly lower rate than those who doesn't. The distribution of reported years of experience of nannies who require sponsorship is much less spread out than those who doesn't. Figure XX shows the number and proportion of users requesting sponsorship by province. Unsurprisingly Ontario has the most foreign users, but provinces such as Quebec suggest higher proportions. Note that the Yukon territory has by far the highest proportion, where 2 out of 11 users where found to be looking for sponsorship, but was removed from the graph due to small counts. 
<!--XX ADD A TABLE BASED ON FIGURE 5 IN ORIGINAL REPORT (boxplots)-->
<!--XX ADD FIGURE 6 BUT REMOVE YUKON-->
```{r fig.width = 10, fig.height = 3.2}
#| fig-cap: Number and proportion of users who require sponsorship by province or territory.
p1 <- data_labeled |> 
  distinct(link, .keep_all = T) |> 
  filter(sponsor == 1, 
         province != "Yukon") |> 
  count(province) |> 
  ungroup() |>
  arrange(n) |>
  mutate(province = factor(province, levels=province)) |> 
  ggplot(aes(n, province, fill = province)) + 
  geom_col(show.legend = F) + theme_bw() +
  geom_text(aes(label = n)) + 
  xlab("Users who require sponsorship") + ylab("") 

p2 <- data_labeled |> 
  filter(province != "Yukon") |> 
  distinct(link, .keep_all = T) |> 
  group_by(province) |> 
  summarise(immigrant_prop = mean(as.numeric(sponsor) == 2), 
            count = n(), 
            immigrant_count = sum(as.numeric(sponsor) == 2)) |> 
  mutate(province = reorder(province, immigrant_count)) |> 
  filter( immigrant_prop < 0.3) |> filter( immigrant_prop > 0) |> 
  ggplot(aes( immigrant_prop, province, fill = province)) + 
  geom_col(show.legend = F) + 
  geom_text(aes(label=round(immigrant_prop, 3))) + 
  ylab("") + xlab("Proportion of immigrant users") + 
  theme_bw() + theme(axis.text.y=element_blank())

grid.arrange(p1, p2, ncol = 2, widths = c(1.3, 1))
```


## Country of origin

The majority of foreign users (78) are originally from the Philippines, followed by Mexico with 21 users. Figure 3 shows the differences in rate distribution and reported years of experience by country of origin. Nannies from the Philippines are willing to take a substantially lower pay than others, with a median hourly rate of less than \$16 CAD and some users even going down to \$12 per hour. Users from Mexico, Japan, Colombia or Brazil have an hourly rate much closer to the global median at \$20 an hour.
<!--XX ADD FIGURE 8-->
<!--XX FOR THE RATE AND EXPERIENCE, ALSO ADD IN THE CANADIANS AS A BASELINE-->

```{r fig.width = 10, fig.height = 3.7}
#| fig-cap: Distribution of rate and years of experience by country of origin.
p2 <- data_labeled |> 
  mutate(country = ifelse(is.na(country), "Canada", country), 
         country = ifelse(country == "United States of America", "US", country)) |> 
  group_by(country) |> 
  mutate(n = n()) |> 
  ungroup() |> 
  mutate(country = reorder(country, n)) |> 
  filter( !is.na(country), n > 3) |> 
  ggplot(aes( rate, country, fill = country)) + geom_boxplot(show.legend = F) + 
  theme_bw() + ylab("") + xlab("Rate (CAD)") +
  scale_x_continuous(breaks = seq(4.0,40.0,4), limits = c(11,38)) 

p3 <- data_labeled |> 
  mutate(country = ifelse(is.na(country), "Canada", country), 
         country = ifelse(country == "United States of America", "US", country)) |> 
  group_by(country) |> 
  mutate(n = n()) |> 
  ungroup() |> 
  mutate(country = reorder(country, n)) |> 
  filter( !is.na(country), n > 3, years_exp < 50) |> 
  ggplot(aes( years_exp, country, fill = country)) + geom_boxplot(show.legend = F) + 
  theme_bw() + ylab("") + xlab("Experience (years)") +
  theme(axis.text.y = element_blank()) + xlim(c(0, 30))

grid.arrange( p2, p3, ncol = 2, widths  = c(1.7, 1.5))
  
```

## Comparison to census data
<!---  XX TODO Add some comparisons to census data by province, citizenship, birth place, and age. -->
We collected data from the 2011 census from IPUMS [ref], on women working in home care and educational support occupations (code 35). Table 4 shows statistics by province. We found 7,652 women in Canada and 34% were from Ontario, significantly lower than what was found on the canadiannanny site, where 52% reported being located in this province. The discrepancy might be due to a lack of Québécois nannies on the site, only 5% reported Quebec as their location, which doesn't match  true population proportions. Census data assigns 15% of people to Quebec. The reasons for this might be that, even though users can write their description in French or any language they want, the site itself is in English with no French version. 
```{r}
possible_nannies <- read_csv("../data/nannies_census.csv")
possible_nannies<- possible_nannies |> 
  mutate(province = case_when(geo1_ca2011 == 10 ~ "Newfoundland", 
                              geo1_ca2011 == 11 ~ "Prince Edward Island", 
                              geo1_ca2011 == 12 ~ "Nova Scotia", 
                              geo1_ca2011 == 13 ~ "New Brunswick", 
                              geo1_ca2011 == 24 ~ "Quebec", 
                              geo1_ca2011 == 35 ~ "Ontario", 
                              geo1_ca2011 == 46 ~ "Manitoba", 
                              geo1_ca2011 == 47 ~ "Saskatchewan", 
                              geo1_ca2011 == 48 ~ "Alberta", 
                              geo1_ca2011 == 59 ~ "British Columbia", 
                              geo1_ca2011 == 60 ~ "Yukon"), 
         citizen = as.factor(citizen), 
         citizenship = as.factor(ifelse(citizen != 4, "Citizen", "Not a citizen")))

possible_nannies |> 
  group_by(province) |> 
  summarise(`N (prop.)` = paste0(n(), 
                      " (", round(n()/dim(possible_nannies)[1], 3), ")"), 
            `Non-citizens (%)` = paste0(round(sum(citizen == 4), 3), 
                               " (", round(mean(citizen == 4), 2)*100, "%)"),
            `Employed (%)` = paste0(round(sum(empstat == 1), 3), 
                               " (", round(mean(empstat == 1), 2)*100, "%)"),
            `Mean Age (sd)` = paste0(round(mean(age), 3), 
                               " (", round(sd(age), 2), ")")) |>
  add_row(province = "National", 
          `N (prop.)` = paste0(dim(possible_nannies)[1]," (1.00)"), 
            `Non-citizens (%)` = paste0(round(sum(possible_nannies$citizen == 4), 3), 
                               " (", round(mean(possible_nannies$citizen == 4), 2)*100, "%)"),
            `Employed (%)` = paste0(round(sum(possible_nannies$empstat == 1), 3), 
                               " (", round(mean(possible_nannies$empstat == 1), 2)*100, "%)"),
            `Mean Age (sd)` = paste0(round(mean(possible_nannies$age), 3), 
                               " (", round(sd(possible_nannies$age), 2), ")")) |>
  rename(`Province` = province) |> 
  kable(format="latex", booktabs = T, caption = "Census statistics by province.") |>
  kable_styling(full_width = F, latex_options = "hold_position", position = "center") |> 
  row_spec(11, hline_after = T) |> 
  column_spec(1, width = "2.7cm")
```

Average age range from 40 to 46 years old with a standard deviation of around 13-14 years across all provinces and at the national level. These numbers are much higher that what was observed from the users on the site, where the mean age was 26.85 at the national level and ranging from 22 to 27 across all provinces. This might indicated that a higher proportion of young people are using the site, and they're using it to find part-time or temporary jobs.

```{r}
possible_nannies |> 
  mutate(citizen = case_when(citizen == 2 ~ "Citizen by birth", 
                             citizen == 3 ~ "Naturalized", 
                             citizen == 4 ~ "Non-citizen"), 
         incearn = incearn/1000) |> 
  group_by(citizen) |> 
  mutate(citizen = paste0(citizen, "\n n = ", n())) |> 
  ungroup() |> 
  ggplot(aes(citizen, incearn, fill = citizen)) + 
  geom_violin(show.legend = F, alpha = 0.8)+
  geom_boxplot(show.legend = F, width = 0.2, fill = "black", alpha = 0.2) + 
  theme_bw() + 
  scale_y_continuous(breaks = seq(0,170.0,20), limits = c(-5,170), 
                     labels = scales::dollar_format(prefix="$", suffix = "k")) +
  ylab("Yearly income") + xlab("")

#possible_nannies |> 
#  group_by(citizenship) |> 
#  mutate(citizenship = paste0(citizenship, "\n n = ", n())) |> 
#  ungroup() |> 
#  filter(incearn < 2e5) |> 
#  ggplot(aes(citizenship, incearn, fill = citizenship)) + 
#  geom_violin(show.legend = F, alpha=0.8) + 
#  geom_boxplot(show.legend = F, fill = "black", alpha = 0.2, width = 0.2) + 
#  theme_bw()
```

Around 6,511 (85%) people were Canadian citizen, out of these 1,251 (16% out of the total) were naturalized immigrants, and 1141 didn't weren't citizens. Table 5 shows census statistics by citizenship status. We can see that naturalized citizens earn a higher yearly income on average than non-citizens and citizens by birth, they also have a higher proportion of people earning more than $50k a year (4.1%) than the other 2 groups, only 0.9% of non-citizens earned more than \$50k in 2011. The income distributions of the both groups of citizens were significantly right-skewed, while the income distribution for non-citizens was slightly skewed to the left. Citizens by birth were more likely to earn negative income, but the proportion of people who are in this situation is quite low in all three groups. Non-citizen had the lowest unemployment rate, with only 2.8%; they were also the youngest group, with a mean age of 39 years, while naturalized citizens were the oldest group at an average of 47 years, makes sense given the time it takes to became a citizen in Canada. 

```{r}
citizen_birth <- possible_nannies |> filter(citizen == 2)
citizen_natur <- possible_nannies |> filter(citizen == 3)
non_citizen <- possible_nannies |> filter(citizen == 4)


possible_nannies |> 
  group_by(citizen) |> 
  summarise(`Mean (k)` = mean(incearn)/1000, 
            `Median (k)` = median(incearn)/1000, 
            `Prop. >50k (%)` = mean(incearn > 50000)*100, 
            `Prop. <0k (%)` = mean(incearn < 0)*100, 
            `Number` = sum(empstat == 2), 
            `Prop. (%)` = mean(empstat == 2)*100, 
            `Mean (years)` = mean(age), 
            `Std. dev. (years)` = sd(age)) |> 
  pivot_longer(cols = -citizen) |> 
  pivot_wider(names_from = citizen) |> 
  kable(format="latex", booktabs = T, caption = "Census statistics by citizenship status.", 
        col.names = c("", paste0("Citizen by birth\nn = ",dim(citizen_birth)[1]), 
                                        paste0("Naturalized\nn = ",dim(citizen_natur)[1]), 
                                        paste0("Non-citizen\nn = ",dim(non_citizen)[1])), 
        digits = 3) |> 
  column_spec(column = 2, width = "3cm") |> 
  column_spec(column = 3, width = "2cm") |> 
  column_spec(column = 4, width = "2cm") |> 
  pack_rows("Income", 1, 4) |> 
  pack_rows("Unemployment", 5, 6) |> 
  pack_rows("Age", 7, 8)
```



# Summary and future work

In this project we utilize the large amounts of data available online to glean insights into the informal childcare sector in Canada. Our work to date has involved extracting almost 10,000 unique nanny profiles and using information retrieval techniques to extract information on age, country of origin, and immigration status. Initial observations suggest some evidence for systematic differences in advertised rates and other characteristics by immigration status and country of origin, with nannies requiring sponsorship willing to charge a lower rate than those who don't on average. 

Future work will focus on several aspects. Firstly, we are working on improving the information retrieval algorithm to extract more information on potential migrants. Secondly, we will investigate image processing techniques to extract information about age and possibly gender from user profile pictures. Finally, we plan to collect multiple waves of profiles over time, in order to get estimates for the implied turnover rates of nannies seeking employment. 

# References

